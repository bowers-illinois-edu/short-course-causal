\documentclass[10pt, letterpaper]{article}
\usepackage{bibentry,natbib,url,comment,amsmath}
\usepackage{graphicx,svn,parskip}
\usepackage{../Styles/sometexdefs}

%\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{tgtermes}

\renewcommand*{\bfdefault}{bx}
\renewcommand{\oldstylenums}[1]{%
  {\fontfamily{pplj}\selectfont #1}}
\usepackage{microtype}

\bibliographystyle{apalike}
\usepackage[letterpaper,bottom=.75in,top=1in,right=1in,lmargin=1.5in]{geometry}

\usepackage[mmddyyyy]{datetime}
\usepackage{advdate}


\usepackage[compact,nobottomtitles*]{titlesec} %nobottomtitles
\titleformat{\part}[hang]{\bfseries\large\scshape}{\hspace{-.5in}\thepart}{.5em}{}{}
\titleformat{\section}[hang]{\large\bfseries}{\hspace{-.5in}\thesection ---}{.25em}{}{}
\titleformat{\subsection}[leftmargin]{\small\bfseries\filleft}{\thesubsection}{.2em}{\hspace{-1in}}{}
\titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}
\titleformat{\paragraph}[runin]{\bfseries}{\theparagraph}{0em}{}{}

%\titlespacing{\part}{0ex}{.5ex plus .1ex minus .2ex}{.25\parskip}
%\titlespacing{\section}{0ex}{1.5ex plus .1ex minus .2ex}{.25\parskip}
\titlespacing*{\section}{-.5in}{1em}{0em}{}%
%\titlespacing{\subsection}{0ex}{.5ex plus .1ex minus .1ex}{1ex}
\titlespacing{\subsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}
\titlespacing{\subsubsection}{0ex}{.5ex plus .1ex minus .1ex}{1ex}
\titlespacing{\paragraph}{0em}{1ex}{.5ex plus .1ex minus .1ex}


\newenvironment{introstuff} {\setcounter{secnumdepth}{0}%
%\newgeometry{lmargin=1.5in}     % use whatever margins you want for left, right, top and bottom.
%   \titlespacing*{\section}{-.75in}{1em}{0em}{}%
%   \titleformat{\subsection}[leftmargin]{\itshape\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}%
%   \titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}%
%   \titleformat{\paragraph}[hang]{\bfseries}{\theparagraph}{0em}{}{}%
%   \titlespacing{\subsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
%   \titlespacing{\paragraph}{0em}{1ex}{0ex plus .1ex minus .1ex}%
%   \titlespacing{\subsubsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
} {\setcounter{secnumdepth}{1}%
\restoregeometry
%  %\titleformat{\part}[hang]{\large\bfseries}{\hspace{-.75in}\thepart}{.5em}{}{}%
%  \titleformat{\section}[hang]{\large\bfseries}{\hspace{-.75in}\thesection---}{.5em}{}{}%
%  \titleformat{\subsection}[leftmargin]{\small\bfseries\filleft}{\thesubsection}{.5em}{\hspace{-.75in}}{}%
%  \titleformat{\subsubsection}[leftmargin]{\itshape\filleft}{\thesubsubsection}{.2em}{\hspace{-.75in}}{}%
%  \titleformat{\paragraph}[runin]{\bfseries}{\theparagraph}{0em}{}{}%
%  % \titleformat{\subsection}[hang]{\itshape}{\thesubsection}{.5em}{}{}%
%  \titlespacing{\section}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
%  \titlespacing{\paragraph}{0em}{1ex}{0ex plus .1ex minus .1ex}%
%  \titlespacing{\subsubsection}{2pc}{1.5ex plus .1ex minus .2ex}{1pc}%
}

% Create new title appearance
\makeatletter
\def\maketitle{%
  %\null
  \thispagestyle{empty}%
  \begin{center}\leavevmode
    \normalfont
    {\large \bfseries\@title\par}%
    {\large \@author\par}%
    {\large \@date\par}%
  \end{center}%
  \null }
\makeatother

\usepackage{fancyhdr}
% \renewcommand{\sectionmark}[1]{\markright{#1}{}}

\fancypagestyle{myfancy}{%
	\fancyhf{}
	% \fancyhead[R]{\small{Page~\thepage}}
	\fancyhead[R]{\small{Matching for Adjustment -- Julio 2020 -- \thepage}}
	\fancyfoot[R]{\footnotesize{Version~of~\input{|"date"}}}
	% \fancyfoot[R]{\small{\today -- Jake Bowers}}
	\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

\newcommand{\entrylabel}[1]{\mbox{\textsf{#1:}}\hfil}

%% These next lines tell latex that it is ok to have a single graphic
%% taking up most of a page, and they also decrease the space arou
%% figures and tables.
\renewcommand\floatpagefraction{.9} \renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9} \renewcommand\textfraction{.1}
\setcounter{totalnumber}{50} \setcounter{topnumber}{50}
\setcounter{bottomnumber}{50} \setlength{\intextsep}{2ex}
\setlength{\floatsep}{2ex} \setlength{\textfloatsep}{2ex}

\specialcomment{com} {\begingroup\sffamily\small\bfseries}{\endgroup}
\excludecomment{com}

\title{Matching for Adjustment and Causal Inference \\
  Escuela de Invierno en M\'{e}todos y An\'{a}lisis de Datos UCU-DCSP }

\author{Jake Bowers \\
  \small{jwbowers@illinois.edu \\
    Online:
    \url{http://jakebowers.org/}}
}

\date{Invierno \the\year}

%\usepackage[pdftex,colorlinks=TRUE,citecolor=blue]{hyperref}
\usepackage[colorlinks=TRUE,citecolor=blue]{hyperref}

\renewcommand{\bibname}{ }
% \renewcommand{\refname}{\normalsize{Required:}}
\renewcommand{\refname}{\vspace{-2em}}

\def\themonth{\ifcase\month\or
  January\or February\or March\or April\or May\or June\or
  July\or August\or September\or October\or November\or December\fi}


\begin{document}
\pagestyle{myfancy}

\begin{introstuff}

\maketitle

  \part{Overview}

  This class is an introduction to statistical adjustment using matched
  stratification in the style pioneered by Rubin and Rosenbaum and currently in
  rapid development across the social science and statistical disciplines. An
  important motivation for matching is to approximate an experimental design or
  at least make an research design in a non-randomized context that can be
  compared to some randomized benchmark. And, since such a motivation arises
  from a desire to make transparent and defensible statements about causal
  relations, we will introduce the counterfactual conception of causal
  inference and the potential outcome formalization of these ideas. We will
  also spend some time on statistical inference (hypothesis testing, confidence
  interval creation) after the creation of a matched design. Finally, we will
  grapple with some of the questions that are current research topics in this
  area: When and how one can claim to have adjusted ``enough''? How can we
  engage with concerns about unobserved confounds even if we have adjusted for
  what we observe?

  Since methods of matching are rapidly developing in the methodology
  literature, we will here focus on the simplest and oldest form:
  post-stratification. The general concepts and work-flow should be
  transportable to more sophisticated methods of matched adjustment.

  \section{Goals and Expectations}

  This course aims to help you think about statistical adjustment using
  stratification and matching as compared to statistical adjustment using the
  linear model directly (adjustment by ``residualization'').

  The course ought to give you opportunities to practice producing
  matched designs for your data and to ask questions that puzzle you as
  you do this work.

  The point of the course is to position you to do the future learning
  that is at the core of your work as an academic analyzing data.

  This course does not delve deeply into the theories of causal
  inference, statistical inference, or algorithms at the heart of these
  methods of statistical adjustment. Rather, through practice using
  tools, I hope that your curiosity is awakened and you begin to read
  more broadly and understand more deeply on your own.

  \subsection{Expectations}

  I assume some previous engagement with high school mathematics,
  probability and statistical computing in the R statistical computing
  environment. If you have not used R, you are welcome to take the
  class, but I encourage you to get a little experience with R before
  the first class session. Feel free to email me to ask for advice about
  how to practice with R before the class begins.

  \subsection{Participation}

  We will be doing hands-on work. I plan to lecture relatively little and
  instead will hope to pose problems of statistical theory, research
  design, and data for you to solve at your computers. I anticipate that
  you'll work in small groups, asking me and/or the group questions as
  you proceed. I will break away to draw on the board or demonstrate on
  my own computer now and then to clarify points or help you around
  particularly difficult tasks.

  \subsection{Computing}

  We will be using R~in class so those of you with laptops available
  should bring them. Of course, I will not tolerate the use of computers
  for anything other than class related work during active class
  time. Please install R~(\url{http://www.r-project.org}) on your
  computers before the first class session. You may prefer to use R in the
  context of the Rstudio IDE (\url{http://www.rstudio.com/}).

  Computing is an essential part of modern statistical data analysis ---
  both for turning data into information and for conveying that information
  persuasively (and thus transparently and reliably) to the scholarly
  community. In this course we will pay attention to computing, with special
  emphasis on understanding what is going on behind the scenes. You will
  be writing your own routines for a few simple and common procedures.

  \section{Books}\vspace{-2em}
  \nobibliography*
  %\nobibliography{/Users/jwbowers/Documents/BIB/big}

  We will use the Rosenbaum book as our primary source. The other books are useful for further study.


  \subsection{Required:}
  \bibentry{rosenbaum2010design} (pdf free to download from some
  university  ip addresses or via university library springerlink
  subscriptions:
  \url{https://link.springer.com/book/10.1007%2F978-1-4419-1213-8}
  )

  \subsection{Recommended:}

  \bibentry{rosenbaum2017} (This book is particularly easy to read. Particularly Chapter 3 on Statistical Inference and Chapter 11 on Matching Techniques.)

  \bibentry{Beck:1986}

  % \bibentry{Bec:1998:Tric}

  \bibentry{berk04}

  \bibentry{gelman2007dau}  (particularly chapters 9,10 and 23 see \url{http://www.stat.columbia.edu/~gelman/arm/}).

  \bibentry{MorWin:2007:Coun} (See \url{http://www.wjh.harvard.edu/~cwinship/cfa.html} for some
  links and background reading)

  \bibentry{rosenbaum:2002} (see \url{http://www-stat.wharton.upenn.edu/~rosenbap/index.html} for lots of papers and presentations).

  \bibentry{Rub:2006:Matc}

\end{introstuff}


  \part{Schedule}

  \textbf{Note: } This schedule is preliminary and subject to change. We will
  spend roughly 4 hours together for three of the days and 3 hours on one of
  the days. I anticipate mixing  group discussions of your questions from the
  readings with in-class work using your own laptops or those provided by the
  school to get practice creating, analyzing, and assessing matched designs.


\section{Experiments, Potential Outcomes, and Treatment Effects}

\subsection{Questions and Reading:}

What is the point of experiments? What are the key characteristics of
experiments? Why are experiments special?

\citealp{kinder1993behalf}

\citealp[Chap 1]{gerber2012field}

How can we bolster the interpretability of our comparisons if we do not have
an experiment? 

\citealp[Chap 1]{rosenbaum2010design}

What do we mean by ``causal inference''? Can we convince ourselves that
experiments have special advantages like ``unbiased estimation of averages of
potential outcomes''?

\citealp[Chap 2]{gerber2012field}

\subsection{Extra Reading:}

\citealp[Chap 9.0 --  9.3]{gelman2007dau} (On potential outcomes and causal
inference)


\citealp[Chap 2]{angrist2009mostly}

\citealp{holland:1986a} (on the Counterfactual/Manipulationist conception of
causality)

\citealp{brady2008cae} (for a survey of other major conceptions of causality from
the perspective of applied social science)



\AdvanceDate[1]
\section{Adjustment by Simple and Complex, Algorithmic Stratification }

Given the problems that arise from the use of the linear model, how can we use
research design to approximate the randomized experiment? How would we assess
whether a matched design adjusted enough or not? What does it mean to adjust
enough? What actual steps do we take in order to flexibly express our ideas
about what it means for ``like to be compared with like.''

\subsection{Questions and Reading:}

Why not use the linear model for adjustment? How do we know when we have
adjusted enough to make a strong case for clear, interpretable comparisons?

\citealp[Chap 6]{rosenbaum2010design}

\citealp[Chap 9.5--9.6]{gelman2007dau}

What is the basic intuition behind post-stratified designs and modern optimal
versions of post-stratification that we call ``matched designs''? What is
``balance''? How do we use R to create and evaluate matched designs?

\citealp[Chap 7--9, 13]{rosenbaum2010design} (Especially Chap 7, Chap 8.6,
Chap 9)

\subsection{Extra:}

\citealp[Chap 3]{rosenbaum2010design} 

\cite{hansen:2004a}

\cite{hansen2011propensity} for an example walk-through of a matched analysis
including a discussion of missing data on covariates.

\cite{ho2007man} [esp. their discussion of model sensitivity, for
example their Fig 2]

Three different ideas about balance testing: (1) \cite{imai2008mae}; (2)
\cite{sekhon2007alternative}\footnote{
  \url{http://sekhon.berkeley.edu/papers/SekhonBalanceMetrics.pdf}}; (3)
\cite{hansen2008cbs} \cite{hansen:statmed:2008} or for a less mathematical
version of the same argument \cite[\S 3]{bowers2011mem}.



\AdvanceDate[1]
\section{Statistical Inference for Matched/Post-stratified Designs}


\subsection{Questions and Reading:}

Given a matched design, how can we produce tests of substantively meaningful
hypotheses about the unobserved comparisons of potential outcomes that we call
``causal effects?''

\citealp[Chap 2]{rosenbaum2010design}

How can we produce  confidence intervals for an estimate of an average
treatment effect?

\citealp[Chap 6.1 and Appendix 6.1]{dunning2012natural}

\citealp[Chap 17]{imbens2009causal}

\subsection{Extra:}

\citealp[Chap 4]{berk04} on general requirements for statistical
inference (i.e. what does it mean to do statistical inference at all, what are
we inferring to?)
%\citet[Appendix A-32 and 33]{fpp07} which summarizes \cite{neyman:1923}


\cite{linlr:2011} provides some useful proofs supporting the idea
that linear regression with ``robust'' HC2 standard errors provides a
useful large-sample way to do statistical inference about average
treatment effects.

\cite{miratrix2012adjusting} teach us about statistical inference for average
treatment effects when matching after experimental outcomes have been
collected.

\cite{freedman2008randomization,freedman2008rae,freedman2007rae,Free:2006:On-t}
Suggesting that even the large sample statistical inference from using
linear regression in randomized experiments is biased. Also arguing
that the Huber-White standard errors are not a good idea.

\cite{rosenbaum:2002a} and \cite{bowers2011fish} showing how
covariance adjustment is compatible with Fisher's randomization
inference (and thus can be unproblematic after matching).

\cite{schochet2009regression,green2009ec} Suggesting that in large
samples these biases worried about by Freedman ought not to worry
us. 

\citealp[Chap 6--8]{imbens2009causal} Suggesting, similarly to Green and
Schochet, that regression is fine for statistical inference in
experiments (and further suggesting the use of the Huber-White robust
standard errors).

\citealp{AbadImbe:2004:On-t} suggesting that the bootstrap is not a good
approach with matched designs.

For advanced reading on the latest in statistical theory for
statistical inference for ``matching estimators'' (which include but
are not restricted to post-stratified studies) see:

\cite{hansen2009prop} for theory using randomization-inference.

\cite{abadie2009matching} for a large-sample, Normal theory approach.


\AdvanceDate[1]
\section{Sensitivity Analysis: An observational study is not a randomized experiment.}

\subsection{Questions and Reading:}

We addressed concerns about variables that we do observe using matching.
Although randomization addresses concerns about all background covariates
(observed and unobserved), any non-randomized study may be criticized on the
basis that it does not adjust for variables that were not observed.

Since an observational study (no matter how well matched) cannot adjust for
unobserved confounders, how can we address concerns about such unobserved
variables?

\cite{cornfield:1959}

\cite{hosman2010}

\subsection{Extra:}

\citealp[Chap 4]{rosenbaum:2002}

\citealp[Chap 3, 14]{rosenbaum2010design}

\cite{imbens2003sea}


\section{*---Other Topics}

If we move quickly, or if the class has some organized preferences, we could
change the syllabus to discussion some of these ideas.


\paragraph{Non-bipartite matching -- Advances in Multivariate Matching: Beyond Binary Treatment }
\citealp[Chap 11]{rosenbaum2010design}; \cite{lu2011optimal}; \cite{imaivandyk:04}

\paragraph{Longitudinal Matching -- Advances in Multivariate Matching: Matching with Longitudinal Data}
\citealp[Chap 12]{rosenbaum2010design}


\section{Stuff that was painfully left out but which is important}

Here are just a few extra citations to launch self-study of aspects of
matching which we did not cover in our class.

The class elected to focus on matching for longitudinal problems for
the last class. We thus are unable to cover other approaches to
matching that have been developed by political methodologists such as
Genetic Matching \citep{diamond2013genetic, sekhon2007multivariate} or
Coarsened Exact Matching \citep{iacus2009causal,
  iacus2011multivariate} or Balance Optimization Subset Selection
\citep{Nikolaevetal:12} or more fine-tuned versions of the optimal
post-stratification that we consider in this class (for example,
\citep{zubizarreta2012using}). Nor did we have time to engage with
many other applied and theoretical topics in causal inference for
observational studies such as the work establishing causal
interpretation of the propensity score (cited in the Rosenbaum
textbook), or the alternative approaches to causal inference based on
weighting by functions of the propensity score such as those arising
from work by Jamie Robins \citep{glynn2010introduction}, let alone
alternative conceptualizations of causal relations such at those
developed by Judea Pearl \citep{JudeaPearl2000a} or the work on
estimation by Heckman or bounding causal inferences by Manski.


\part{References}

\bibliography{/Users/jwbowers/Documents/PROJECTS/Research-Group-Bibliography/big}

\end{document}

