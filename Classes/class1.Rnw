
% For LaTeX-Box: root = class1.tex 
% search and replace keep.comment=FALSE to TRUE for commented version
\documentclass[10pt,letterpaper]{article}
\usepackage{fontspec}

\title{Session 1 --- Matching Short Course}

\author{Jake Bowers}

\usepackage{../Styles/ps531}


\includeversion{comment}
\markversion{comment}
%\excludeversion{comment}

\begin{document}

<<include=FALSE,cache=FALSE>>=
opts_chunk$set(tidy=TRUE,echo=TRUE,results='markup',strip.white=TRUE,fig.path='figs/fig',cache=FALSE,highlight=TRUE,width.cutoff=132,size='footnotesize',out.width='1.2\\textwidth',message=FALSE,comment=NA)
@

\maketitle

\begin{enumerate}
    \setcounter{enumi}{-1}
  \item Today we'll work with a dataset that documents a public policy
    intervention. In 2004 the municipality of Medell\'{i}n, Columbia built
    built the first line of the Metrocable --- a set of cable cars that
    connected poor neighborhoods on the edges of the city to the center of the
    city. Professor Magdalena Cerd\'{a} and her collaborators asked whether
    this kind of integration could have an effect on violence in these poor
    (and heretofore violent) neighborhoods. We have some of the data from this
    project to use here.\footnote{The article was published in the American
    Journal of Epidemiology in 2012.}

    The data Cerd\'{a} collected tell us about the roughly 50 neighborhoods in
    the study, about half of which had access to the Metrocable line and half
    did not. You can load the data here:

%    {\centering
%    \includegraphics[width=.5\textwidth]{MedellinNeighborhoods.pdf}
%    }

    
<<>>=
load("../Resources/Cerdaetal/meddat.rda")
@

I don't have a formal codebook but here are my guesses about the meanings of
some of the variables:

\begin{Verbatim}
  ## Covariates
nh03         Neighborhood id
nhGroup      Treatment (T) or Control (C)
nhTrt        Treatment (1) or Control (0)
nhHom        Mean homicide rate per 100,000 population in 2003
nhClass      __
nhSisben     __
nhPopD       __
nhDistCenter Distance to city center (km)
nhQP03       __
nhPV03       __
nhTP03       __
nhBI03       __
nhCE03       __
nhNB03       __
nhMale       __
nhAgeYoung   __
nhAgeMid     __
nhMarDom     __
nhSepDiv     __
nhOwn        __
nhRent       __
nhEmp        __
nhAboveHS    __
nhHS         __
nhLogHom     Log Homicide (i.e. log(nhHom))

## Outcomes
BE      Neighborhood amenities Score 2008-2003
CE      Collective Efficacy Score 2008-2003
PV      Perceived Violence Score 2008-2003
QP      Trust in local agencies Score 2008-2003
TP      Reliance on police Score 2008-2003
hom     Homicide rate per 100,000 population Score 2008-2003 (in differences in log odds)
\end{Verbatim}

Let us first do a very simple analysis to get concepts clear. 

I will write $Z_i=1$ to mean that a neighborhood $i$ was assigned
intervention 1 (in this case, a Metrocable station), $y_{i,Z=1} \equiv y_{i,1}$
to refer to the \emph{potential outcome} for a neighborhood assigned
intervention and $y_{i,Z=0} \equiv y_{i,0}$ to refer to the counterfactual
condition in which neighborhood $i$ did not receive the intervention.

I will also say that the Metrocable intervention had a \emph{causal effect} if
$y_{i,1} \ne y_{0,i}$ (and no causal effect if $y_{i,1} = y_{i,0}$).

We tend to have two ways to use observed data ($Z$, the observed assignment of
the intervention), and $Y$ (the observed outcome), to give us a hint about the
relationship between $y_{i,1}$ and $y_{i,0}$ (and thus to give us a hint about
causal effects. I say, "hint", because, the fact that \emph{we cannot know the true
relationship between potential outcomes} is often called the "Fundamental
problem of causal inference" \citep{holland:1986a,brady2008cae}.

First, and simplest, we can say, "We do not know the true relationship between
potential outcomes, but we can articulate a hypothesis about that relationship
and then test this hypothesis." \cite{fisher:1935, rosenbaum2010}. This is
what I call the "testing approach."

Second, and perhaps most commonly, we can say, "We do not know the true
relationship at the individual level of $y_{i,1}$ and $y_{i,0}$, but we can
estimate the relationship between averages of them ($\bar{y}_{1}$ and
$\bar{y}_{0}$) \cite{neyman:1923,angrist2009mostly}. I call this the
"estimation approach."

Let us start with estimation.

\item Estimate and interpret the average effect of the intervention on one of the outcomes
  of your choice. If you are using \texttt{hom}, I would advise using
  \texttt{exp(hom)} to get back to the original scale.


  \begin{comment}

<<>>=

atePV<-lm(PV~nhTrt,data=meddat)
atePV

@

\end{comment}

\item What does this number have to do with $y_{i,1}$ and $y_{0,i}$? (Maybe we
  should discuss this as a group.) Here are some hints and ideas to help
  orient discussion. Below the math, I make the same demonstration by
  simulation.

 
    \citet{neyman:1923} proposed (1) that we decide to stop focusing on the
    individual level causal effects and instead be interested in $\bar{\tau}=
    (1/n) (\sum_{i=1}^n r_{1i}) - (1/n) (\sum_{i=1}^n r_{0i}) = \bar{r}_{1} -
    \bar{r}_{0}$ (i.e. he suggested we choose to care about mean differences
    of the counterfactuals rather than any individual counterfactuals
    themselves) and (2) he claimed that $\hat{\bar{\tau}}=(1/m)\sum_{i=1}^n
    Z_i R_i - (1/(n-m))\sum_{i=1}^n (1-Z_i) R_i$ was a good \textbf{estimator}
    of $\bar{\tau}$ (where $R_i$ is observed outcomes and relates to potential
    outcomes via $R_i=Z_i r_{1i}+(1-Z_i) r_{0i}$, $m$ is number of treated
    observations and $n$ is total number of observations). We are going to
    prove this is the case, for a specific understanding of ``good''.   
 
    Neyman, chose the idea of ``unbiasedness'' for ``good''.
    An unbiased estimator is an estimator (i.e. a formula that when
    repeatedly applied to the data (across samples, across
    assignments, etc..) produces a distribution --- a sampling
    distribution, a randomization distribution), where the mean of
    this distribution is the ``true'' value in the ``population'' (or
    the experimental pool). In Neyman's example, the population is the
    set of agricultural fields to which he wants to assign fertilizer
    treatments. For us, it is these 48 neighborhoods. We can think of
    experimental pools as ``finite populations.'' We can write this
    overly wordy definition concisely like this:
  $$E_{R}[\hat{\bar{\tau}}]=\bar{\tau},$$
  where $E_{R}$ (the ``expected value'') is ``the average across all
  ways to draw assignments, $Z$, from the urn.'' You'll mostly just
  see something like $E[\hat{\beta}]=\beta$ as a statement that
  whatever formula is giving you $\hat{\beta}$ is, on average across
  imaginary replications, equal to $\beta$ --- is unbiased. Now, the
  expectation operator, $E$ has a kind of algebra associated with it
  such that $E[aX]=aE[X]$ if $X$ is something that can vary and $a$ is
  some constant, or $E[X+Y]=E[X]+E[Y]$ if $X$ and $Y$ both vary
  independently (or $E[aX_1+aX_2+\ldots]=a(E[X_1]+E[X_2]+\ldots)$).
  
  Here is an incomplete version of the derivation that shows that, in
  fact, the observed sample difference of means can tell us something
  about the unobserved population difference of means, and, in fact,
  will be, on average, equal to the unobserved population difference
  of means: i.e. that the sample difference of means is an unbiased
  estimator of the population difference of means. 
  
  We want to show that $E_{R}[\hat{\bar{\tau}}]=\bar{\tau}$. Here only
  $Z_i$ is random. And, I can tell you that $E_{R}[Z_i]=m/n$ (what
  does this mean?). I use $E_R$ at first just to be clear that we are
  taking expectations over the possible randomizations. Mostly you'll
  just see people use $E$ without a discussion of the space over which the expectations are to be taken.
  
  
     
  \begin{align}
    E_{R}\left[ \hat{\tau} \right]&=E_{R}\left[ \sum_{i=1}^n Z_i \frac{R_{i}}{m}-\sum_{i=1}^n (1-Z_i) \frac{R_{i}}{n-m} \right] \\
    \intertext{recall that $R_{i}=Z_i r_{1i} + (1-Z_i) r_{0i}$ or $R_i=r_{0i}$ when $Z_i=0$, etc.}
    &=E \left[ \sum_{i=1}^n Z_i \frac{r_{1i}}{m} \right]-E \left[ \sum_{i=1}^n (1-Z_i) \frac{r_{0i}}{n-m} \right] \\
    \intertext{recall that only $Z$ is random and that $E_R[Z_i]=m/n$ because no pairs for now}
    &=\sum_{i=1}^n \frac{m}{n} \frac{r_{1i}}{m}-\sum_{i=1}^n (1-\frac{m}{n}) \frac{r_{0i}}{n-m} \\
    \intertext{now $(1-(m/n)=(n-m)/n$ }
    &=\sum_{i=1}^n \frac{r_{1i}}{n}-\sum_{i=1}^n \frac{r_{0i}}{n} \\
    &=\bar{r}_{1i}-\bar{r}_{0i}=\bar{\tau}
  \end{align}

  

  

\item Here is the same demonstration by simulation. Let's talk about what is
  going on here. 

<<>>=

y0<-meddat$PV ## we could have also use y0<-rnorm(48) or something else
y1<-y0+1


newexperiment<-function(origZ,y1,y0){
  Znew<-sample(origZ)
  Y<-Znew*y1+(1-Znew)*y0
  epthat<-mean(Y[Znew==1] - mean(Y[Znew==0]))
  return(epthat)
}


## set.seed(123456)
randdist<-replicate(1000,newexperiment(origZ=meddat$nhTrt,y1=y1,y0=y0))

summary(randdist)

@

What is this a plot of?

<<out.width='.5\\textwidth'>>=
plot(density(randdist))
rug(randdist)
rug(1,ticksize=.3,lwd=2,col="blue")
rug(mean(randdist),ticksize=.3,lwd=2,col="red")

@


\item Now, let us explore the testing approach to statistical inference for
  causal effects.

<<>>=
@




\end{enumerate}





\bibliographystyle{apalike}
\bibliography{/Users/jwbowers/Documents/PROJECTS/BIB/big}




\end{document}
