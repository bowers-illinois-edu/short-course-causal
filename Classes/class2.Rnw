
% For LaTeX-Box: root = class2.tex
% search and replace keep.comment=FALSE to TRUE for commented version
\documentclass[10pt,letterpaper]{article}
%\usepackage{fontspec}
%\usepackage{ulem}

\title{Session 2 --- Matching Short Course}

\author{Jake Bowers}

\usepackage{../Styles/ps531}


\includeversion{comment}
\markversion{comment}
%\excludeversion{comment}

\begin{document}
%\normalem

<<include=FALSE,cache=FALSE>>=
opts_chunk$set(tidy=TRUE,echo=TRUE,results='markup',strip.white=TRUE,fig.path='figs/fig',cache=FALSE,highlight=TRUE,width.cutoff=132,size='footnotesize',out.width='1.2\\textwidth',message=FALSE,comment=NA)
@

\maketitle

\begin{enumerate}
    \setcounter{enumi}{-1}
  \item  We'll continue to work with the Cerd\'{a} et al data. We completed
    some statistical and conceptual preliminaries yesterday. Today we have two
    goals (1) convince ourselves that, while linear models may be excellent
    at estimating effects, they are not well suited for transparent
    adjustment and (2) create a matched design for the Cerd\'{a} et al study.

<<>>=
load(url("http://jakebowers.org/Matching/meddat.rda"))
## or, if that doesn't work
meddat<-read.csv(url("http://jakebowers.org/Matching/meddat.csv"))
@

I don't have a formal codebook but here are my guesses about the meanings of
some of the variables:

\begin{Verbatim}
## Some Covariates
nh03         Neighborhood id
nhGroup      Treatment (T) or Control (C)
nhTrt        Treatment (1) or Control (0)
nhHom        Mean homicide rate per 100,000 population in 2003
nhDistCenter Distance to city center (km)
HomCount2003 Number of homicides in 2003
Pop2003      Population in 2003
HomCount2008 Number of homicides in 2008
Pop2008      Population in 2008
\end{Verbatim}

\item Now, the Metrocable intervention was not a randomized experiment. And in
  most social science papers, we would tend to see something like the
  following table. What does the treatment effect mean in this table?  Why
  would someone report the effect shown in the table instead of the simple
  estimate of the average treatment effect that we calculated before? What are
  some of the strengths and weaknesses of this approach to \emph{statistical
  adjustment}?

<<>>=
library(xtable)

## Convert counts to rates per 1000 people (to adjust for population)
meddat$HomRate03<-with(meddat, (HomCount2003/Pop2003)*1000)
meddat$HomRate08<-with(meddat, (HomCount2008/Pop2008)*1000)

newformula<-reformulate(c("nhTrt",names(meddat)[5:24],"HomRate03"),response="HomRate08")
lm1<-lm(newformula,data=meddat)
xtablm1<-xtable(lm1,digits=2)
@

<<results='asis'>>=
print(xtablm1,floating=FALSE)
@

\item Now, let's simplify this approach a bit so that we can understand what
  is happening. Let us choose one variable as a "control", say, the baseline
  homicide rate as of 2003. Here is some code to work with and understand.

<<results='hide'>>=
lm2<-lm(HomRate08~nhTrt+HomRate03,data=meddat)
summary(lm2)
@

Here is one bit of evidence showing how a linear model "controls for" the effects of
background covariates:

<<results="hide">>=
e.outcome<-resid(lm(HomRate08~HomRate03,data=meddat))
e.treatment<-resid(lm(nhTrt~HomRate03,data=meddat))
lm2a<-lm(e.outcome~e.treatment)
coef(lm2a)[[2]]
all.equal(coef(lm2a)[[2]],coef(lm2)[["nhTrt"]])
@

And, here is another view of this small bit of adjustment (thick black line is
the predicted line for the treatment group, thin line is for the control
group):

\begin{minipage}{.5\textwidth}
<<fig1,fig.keep='none',echo=TRUE,tidy=FALSE>>=
with(meddat, plot(HomRate03,HomRate08,pch=c(1,19)[nhTrt+1],
		  xlab="Homicides/1000 (2003)",
		  ylab="Homicides/1000 (2008)"))
abline(coef(lm2)[1]+coef(lm2)[2]*0,coef(lm2)[3])
abline(coef(lm2)[1]+coef(lm2)[2]*1,coef(lm2)[3],lwd=2)
@
\end{minipage}
\begin{minipage}{.5\textwidth}
<<printfig1,echo=FALSE,out.width='.80\\textwidth'>>=
<<fig1>>
@
\end{minipage}

So, what should we make of this attempt to adjust for baseline outcomes? Was
it successful? How would we know? What is the problem that the graph suggests?


\item How about adding another variable? Here, I add population density to the
  model for adjustment.


<<results="hide">>=

lm3<-lm(HomRate08~nhTrt+HomRate03+nhPopD,data=meddat)
summary(lm3)

@

What does this plot suggest about extrapolation and functional form dependence
if we were to try to do linear model based adjustment for these two variables?

{\centering
<<out.width='.4\\textwidth'>>=
with(meddat,plot(HomRate03, nhPopD,pch=c(1,19)[nhTrt+1],
		  xlab="Homicides/1000 (2003)",
		  ylab="Population Density"))

@
}

\item One idea, proposed by \citet{hansen:bowers:2008}, is to test whether
  neighborhoods might differ from one another on the different covariates that
  we aim to adjust for. Because we out hypothesis refers to an experiment, we
  compare the differences in standardized means that we observe to the
  distribution of differences we would observe in a large randomized
  experiment with the same design. A well run and large experiment would
  display very little differences between treated and control groups in terms
  the distributions of the covariates.

  The \texttt{xBalance} function in the \texttt{RItools} package  It also
  reports a hypothesis test for an omnibus or overall hypothesis: that, across
  all of the covariates, the configuration of mean differences is equivalent
  to that we would see in a randomized experiment.

  Please interpret the following results.

<<results='hide'>>=
library(RItools)
options(digits=3,scipen=5)
balfmla<-update(newformula,nhTrt~.-nhTrt)
xb1<-xBalance(balfmla,strata=list(raw=NULL),
	      data=meddat,report="all")
#print(xb1)

round(xb1$results,3)
xb1$overall

thextab<-xtable(xb1,digits=3)
@

<<eval=FALSE,results='asis'>>=
## Not run
print(thextab,floating=FALSE)
@

<<out.width='.5\\textwidth'>>=
plot(xb1,
     which.vars=names(xb1$results[order(xb1$results[,"p","raw"]),"p",]))
@


\item What kinds of strengths and weaknesses do you see in this balance
  assessment method? How might we overcome them?

\item How to improve balance? One idea is to make groups of neighborhoods
  which are similar on important background variables. \citet{hansen:2004}
  demonstrated one method for making such sets. Here, we will try it with just
  one background variable, the baseline outcome, because we  imagine that it
  is the most important one.

  The input to the matching algorithm is a distance matrix.

<<>>=
library(optmatch)

tmp <- meddat$HomRate03
names(tmp) <- rownames(meddat)

absdist <- match_on(tmp, z = meddat$nhTrt)

str(absdist)
absdist[1:5,1:5]
@

And the call to full matching is like this:

<<>>=

fm0<-fullmatch(absdist,data=meddat)
summary(fm0)

@

Let's interpret this output and then we can talk a bit about what fullmatch is
doing.


\item The \texttt{optmatch} package produces optimal full matched designs. The
  designs are "full" because, by default, no observations are deleted (we will
  delete observations later). The designs are "optimal"  (the final design
  minimizes the average weighted distance across all matched sets) rather than
  "greedy" (the final design minimizes the distances between units in order).
  Let's get clear about how greedy algorithms work. And get some intuition for
  optimal algorithms.


\item When we have more than one variable to match on, current approaches try
  to produce a score that simplifies the problem without losing too much
  information. In the Rosenbaum book, for example, he uses the Mahalnobis
  distance:

<<results="hide">>=
library(optmatch)

mahalDist<-match_on(nhTrt~HomRate03+nhPopD,data=meddat)
str(mahalDist)
mahalDist[1:5,1:5]

fm1<-fullmatch(mahalDist,data=meddat)

summary(fm1)


@


And now to assess balance
<<assessbalance>>=
xb2<-xBalance(balfmla,
	      strata=list(raw=NULL,fm1=~fm1),
	      data=meddat,report="all")

xb2$overall

@


<<out.width='.5\\textwidth'>>=
plot(xb2,
     which.vars=dimnames(xb2$results[order(xb2$results[,"p","raw"]),"p",])[["vars"]]
     )

@

\item Now, above we used a Mahalanobis Distance to (1) reduce the dimension of
  the covariate space (i.e. from 2 covariates to 1 score) and (2) to represent
  the distance or relationships between the treated and control units.
  Another common dimension reduction metric is the propensity score. Here is
  how one might calculate a propensity score, match on it, and assess balance.


<<>>=

glm1<-glm(nhTrt~HomRate03+nhPopD,data=meddat,family=binomial())
## psDist<-match_on(glm1)
meddat$pScore<-predict(glm1)
psDist<-match_on(nhTrt~pScore,data=meddat)
fm2<-fullmatch(psDist,data=meddat)
summary(fm2,min.controls=0,max.controls=Inf)

xb3<-xBalance(update(balfmla,.~.+pScore),
	      strata=list(raw=NULL,fm1=~fm1,fm2=~fm2),
	      data=meddat,report="all")

xb3$overall


@


\item Now that we have some sense about how to interpret balance assessments
  and make matched designs, can we make a better matched design? What is the
  best you can create?

\end{enumerate}


% Next: how to know if your test is a good test (analogy to bias)



\bibliographystyle{apalike}
\bibliography{/Users/jwbowers/Documents/PROJECTS/BIB/big}




\end{document}
