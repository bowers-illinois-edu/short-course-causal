
% For LaTeX-Box: root = class1.tex 
% search and replace keep.comment=FALSE to TRUE for commented version
\documentclass[10pt,letterpaper]{article}
\usepackage{fontspec}
\usepackage{ulem}

\title{Session 2 --- Matching Short Course}

\author{Jake Bowers}

\usepackage{../Styles/ps531}


\includeversion{comment}
\markversion{comment}
%\excludeversion{comment}

\begin{document}
\normalem

<<include=FALSE,cache=FALSE>>=
opts_chunk$set(tidy=TRUE,echo=TRUE,results='markup',strip.white=TRUE,fig.path='figs/fig',cache=FALSE,highlight=TRUE,width.cutoff=132,size='footnotesize',out.width='1.2\\textwidth',message=FALSE,comment=NA)
@

\maketitle

\begin{enumerate}
    \setcounter{enumi}{-1}
  \item  We'll continue to work with the Cerd\'{a} et al data.
    
    
<<>>=
load(url("http://jakebowers.org/Matching/meddat.rda"))
## or, if that doesn't work
meddat<-read.csv(url("http://jakebowers.org/Matching/meddat.csv"))
@

I don't have a formal codebook but here are my guesses about the meanings of
some of the variables:

\begin{Verbatim}
## Some Covariates
nh03         Neighborhood id
nhGroup      Treatment (T) or Control (C)
nhTrt        Treatment (1) or Control (0)
nhHom        Mean homicide rate per 100,000 population in 2003
nhDistCenter Distance to city center (km)
HomCount2003 Number of homicides in 2003
Pop2003      Population in 2003
HomCount2008 Number of homicides in 2008
Pop2008      Population in 2008
\end{Verbatim}

\item Now, the Metrocable intervention was not a randomized experiment. And in
  most social science papers, we would tend to see something like the
  following:


<<>>=
library(xtable)

## Convert counts to rates per 1000 people (to adjust for population)
meddat$HomRate03<-with(meddat, (HomCount2003/Pop2003)*1000)
meddat$HomRate08<-with(meddat, (HomCount2008/Pop2008)*1000)

newformula<-reformulate(c("nhTrt",names(meddat)[5:24],"HomRate03"),response="HomRate08")
lm1<-lm(newformula,data=meddat)
xtablm1<-xtable(lm1,digits=2)
@

<<results='asis'>>=
print(xtablm1,floating=FALSE)
@

Why would someone report the effect shown in the table above instead of the
simple effect that we calculated before? What are some of the strengths and
weaknesses of this approach to \emph{statistical adjustment}?


\item Now, let's simplify this approach a bit. Let us choose one variable as a
  "control", say, the baseline homicide rate as of 2003. Here is some code to
  work with and understand.
  
<<results='hide'>>=

lm2<-lm(HomRate08~nhTrt+HomRate03,data=meddat)
summary(lm2)

@

<<out.width=".6\\textwidth">>=

with(meddat, plot(HomRate03,HomRate08,pch=c(1,19)[nhTrt+1],
		  xlab="Homicides/1000 (2003)",
		  ylab="Homicides/1000 (2008)"))
abline(coef(lm2)[1]+coef(lm2)[2]*0,coef(lm2)[3])
abline(coef(lm2)[1]+coef(lm2)[2]*1,coef(lm2)[3],lwd=2)

@

So, what should we make of this attempt to adjust for baseline outcomes? Was
it successful? How would we know? What is the problem that the graph suggests?


\item How about adding another variable? 


\item One idea, proposed by \citet{hansen:bowers:2008}, is to ask whether and
  how neighborhoods might differ from one another on the different covariates
  that we aim to adjust for. And, to compare those differences to the kinds of
  differences that would be typical of a randomized experiment (with the same
  size study and same randomization scheme). Here is one way to assess these
  differences. \texttt{xBalance} compares the differences of means observed in
  the data with the distributions of differences of means that we would see in
  a randomized experiment with no effects. It also reports a hypothesis test
  for the hypothesis that no linear combination of covariates differed
  (the overall, or "omnibus", balance test).


  Please interpret the following results.

<<>>=
library(RItools)

balfmla<-update(newformula,nhTrt~.-nhTrt)
xb1<-xBalance(balfmla,strata=list(raw=NULL),
	      data=meddat,report="all")

print(xb1)
@


<<out.width='.5\\textwidth'>>=
plot(xb1,
     which.vars=names(xb1$results[order(xb1$results[,"p","raw"]),"p",])
     )

@


\item How to improve balance? Here is one idea, which I show with just a few
  variables, but which I hope you improve. First, let's try to understand the
  output and what optmatch is doing.

<<results="hide">>=
library(optmatch)
##meddat$nhDistCenterF<-factor(meddat$nhDistCenter)
##with(meddat,table(nhDistCenter,nhDistCenterF,exclude=c()))

mahalDist<-match_on(nhTrt~HomRate03+nhDistCenter,data=meddat)

fm1<-fullmatch(mahalDist,data=meddat)

summary(fm1)

xb2<-xBalance(balfmla,
	      strata=list(raw=NULL,fm1=~fm1),
	      data=meddat,report="all")

@


<<out.width='.5\\textwidth'>>=
plot(xb2,
     which.vars=dimnames(xb2$results[order(xb2$results[,"p","raw"]),"p",])[["vars"]]
     )

@

Now trying a propensity score with a different variable:

<<>>=

glm1<-glm(nhTrt~HomRate03+nhPopD,data=meddat,family=binomial())
## psDist<-match_on(glm1)
meddat$pScore<-predict(glm1)
psDist<-match_on(nhTrt~pScore,data=meddat)
fm2<-fullmatch(psDist,data=meddat)
summary(fm2,min.controls=0,max.controls=Inf)

xb3<-xBalance(update(balfmla,.~.+pScore),
	      strata=list(raw=NULL,fm1=~fm1,fm2=~fm2),
	      data=meddat,report="all")


@


\end{enumerate}


% Next: how to know if your test is a good test (analogy to bias)



\bibliographystyle{apalike}
\bibliography{/Users/jwbowers/Documents/PROJECTS/BIB/big}




\end{document}
