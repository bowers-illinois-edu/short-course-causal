

% For LaTeX-Box: root = class3.tex
% search and replace keep.comment=FALSE to TRUE for commented version
\documentclass[10pt,letterpaper]{article}
%\usepackage{fontspec}
\usepackage{ulem}

\title{Session 4 --- Matching Short Course}

\author{Jake Bowers}

\usepackage{../Styles/ps531}


\includeversion{comment}
\markversion{comment}
%\excludeversion{comment}

\begin{document}
\normalem

<<include=FALSE,cache=FALSE>>=
opts_chunk$set(tidy=TRUE,echo=TRUE,results='markup',strip.white=TRUE,fig.path='figs/fig',cache=FALSE,highlight=TRUE,width.cutoff=132,size='footnotesize',out.width='1.2\\textwidth',message=FALSE,comment=NA)

options(width=110,digits=3)
@

\maketitle

\begin{enumerate}
    \setcounter{enumi}{-1}
  \item  We'll continue to work with the Cerd\'{a} et al data. We completed
    some statistical and conceptual preliminaries on Monday. On Tuesday, we
    started work on making simple matched designs after we confronted some of
    the problems with the use of linear models for statistical adjustment.
    Yesterday, we matched on many variables at once using scores (like the
    Mahalanobis distance score or the propensity score) and struggled with
    some of the problems that score estimation raises, then we used calipers to
    allow the matching algorithm to choose to delete some observations and
    spent some time learning about the observations that the algorithm chose
    to delete, and finally we learned how to estimate an average treatment
    effect (and made some experiments to figure out which proposals for effect
    estimation are unbiased). 

    Today we will create confidence intervals and calculate $p$-values for our
    estimates and also work on one approach to sensitivity analysis.

<<>>=
load(url("http://jakebowers.org/Matching/meddat.rda"))
## or, if that doesn't work
## meddat<-read.csv(url("http://jakebowers.org/Matching/meddat.csv"))
@


Before we begin you should create the outcome variables and useful formulas
<<>>=
meddat$HomRate03<-with(meddat, (HomCount2003/Pop2003)*1000)
meddat$HomRate08<-with(meddat, (HomCount2008/Pop2008)*1000)
newformula<-reformulate(c("nhTrt",names(meddat)[5:24],"HomRate03"),response="HomRate08")
balfmla<-update(newformula,nhTrt~.-nhTrt-nhDistCenter)
@

\item Let's start with your favorite matched design from last time. Here is
  mine (not really a favorite, but a matched design that I can use for
  demonstration.)

<<>>=
## install.packages("glmnet",dependencies=TRUE)
library(glmnet) 
library(RItools)
library(optmatch)

## Scalar distance on baseline outcome
tmp <- meddat$HomRate03
names(tmp) <- rownames(meddat)
absdist <- match_on(tmp, z = meddat$nhTrt)
X<-model.matrix(update(balfmla,.~.-1),data=meddat)
y<-meddat$nhTrt
set.seed(12345)
ridge1cv<-cv.glmnet(X,y,family="binomial",alpha=0,type.measure="class")
pScore<-predict(ridge1cv,newx=X,s="lambda.1se")[,1]
stopifnot(all.equal(names(pScore),row.names(meddat)))
meddat$pScore<-pScore
psDist<-match_on(nhTrt~pScore,data=meddat)

##Other pscores (may be faster and easier)
## install.packages("brglm",dependencies=TRUE)
library(brglm)
brglm1<-brglm(balfmla,data=meddat,family=binomial)
pScore2<-predict(brglm1)
meddat$pScore2<-pScore2
psDist2<-match_on(nhTrt~pScore2,data=meddat)

## Overlapping propensity score plot
## par(mfrow=c(1,2))
## with(meddat,boxplot(split(pScore2,nhTrt)))
## with(meddat,boxplot(split(pScore,nhTrt)))

## Mahalanobis distance
meddatRanks<-as.data.frame(sapply(meddat[,all.vars(balfmla)],rank))
row.names(meddatRanks)<-row.names(meddat)
meddatRanks$nhTrt<-meddat$nhTrt

mahalDist<-match_on(balfmla,data=meddat)

## Match on mahalanobis distance plus two calipers
### Use the calipers to exclude really bad matches.
quantile(as.vector(mahalDist),seq(0,1,.1))
quantile(as.vector(psDist),seq(0,1,.1))
quantile(as.vector(psDist2),seq(0,1,.1))
quantile(as.vector(absdist),seq(0,1,.1))

fm1<-fullmatch(mahalDist+caliper(psDist2,3),data=meddatRanks,tol=.00001)
fm2<-fullmatch(psDist2+caliper(psDist2,3),data=meddat,tol=.00001,min.controls=.25,max.controls=4)
pm2<-pairmatch(psDist2,data=meddat,tol=.00001,remove.unmatchables=TRUE)
## pm2<-pairmatch(mahalDist+caliper(psDist2,4),data=meddat,tol=.00001,
##		remove.unmatchables=TRUE)
## fm2a<-fullmatch(psDist+caliper(psDist,3),data=meddat,tol=.00001)
##fm2a<-fullmatch(absdist+caliper(psDist2,3),data=meddat,tol=.00001)

xb1<-xBalance(update(balfmla,.~.+pScore2),
	      strata=list(raw=NULL,fm1=~fm1,fm2=~fm2,pm2=~pm2),
	      data=meddat,
	      report=c("std.diffs","z.scores","adj.means",
		       "adj.mean.diffs", "chisquare.test","p.values"))
xb1$overall

summary(fm1,min.controls=0,max.controls=Inf)
table(matched(fm1))
summary(fm2,min.controls=0,max.controls=Inf)
table(matched(fm2))


@

\item Here are two treatment effects estimated using the harmonic mean
  weighting that I like (plus the unadjusted effect):

<<>>=

lmRaw<-lm(HomRate08~nhTrt,data=meddat)
lmFm1<-lm(HomRate08~nhTrt+fm1,data=meddat)
lmFm2<-lm(HomRate08~nhTrt+fm2,data=meddat)

ateRaw<-coef(lmRaw)[["nhTrt"]]
ateFm1<-coef(lmFm1)[["nhTrt"]]
ateFm2<-coef(lmFm2)[["nhTrt"]]

c(ateRaw,ateFm1,ateFm2)

@

If we tested a hypothesis about one of these effects, what would it mean?
(i.e. Imagine that we said, $H_0: \tau=0$ and got $p=.02$, how would you
explain this to an educated person who is not a statistician?)

\item 




\end{enumerate}


% Next: how to know if your test is a good test (analogy to bias)



\bibliographystyle{apalike}
\bibliography{/Users/jwbowers/Documents/PROJECTS/BIB/big}




\end{document}
