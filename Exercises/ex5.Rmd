---
title: 'Exercise 5: Experimenting with Non-Bipartite Matching"
author: 'Jake Bowers'
date: '`r format(Sys.Date(), "%B %d, %Y")`'
header-includes:
  - \usepackage{bm}
output:
  pdf_document:
    number_sections: true
    fig_caption: yes
    fig_height: 8
    fig_width: 8
    latex_engine: xelatex
    citation_package: biblatex
    keep_tex: true
fontsize: 10pt
geometry: margin=1in
graphics: yes
mainfont: "Helvetica"
bibliography: classbib.bib
biblio-style: "authoryear-comp,natbib"
---

<!-- This is a comment -->
<!-- Make this document using library(rmarkdown); render("exploration1.Rmd") -->
<!-- \input{mytexsymbols} -->

```{r setup, echo=FALSE, results=FALSE, include=FALSE, cache=FALSE}
library(here)
source(here("rmd_setup.R"))
```

The primary goal of this exercise is for you to play around with non-bipartite
matching. You can either use the Medellin data or your own data:

1. If you are using the Medellin data, one idea would be to compare
   neighborhoods that are as similar as possible in baseline homicide rate,
   `HomRate03` but that differ as much as possible in `nhTrt` (receipt of a
   Metrocable station). You can match on `HomRate03` first and then see how
   many pairs differ in receipt of a Metrocable station. If very few pairs
   differ, you could try to add a penalty for similarity on `nhTrt`. You could
   also match on propensity or mahalanobis differences. Obviously the Medellin
   data does not lend itself easily to non-bipartite matching.

OR

2. You could try something similar with your own data. The idea is to create
   sets that differ little on some background covariates --- perhaps individual
   covariates, perhaps scores/indices --- but that differ as much as possible
   on the key explanatory or causal driver.

# References

